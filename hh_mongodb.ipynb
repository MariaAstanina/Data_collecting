{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hh_mongodb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQEmk3ScKSJ0PdPShqNEGj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chGD0Xa9b-8N"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from random import uniform\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "from bs4 import BeautifulSoup as BS\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import *\n",
        "\n",
        "occupation = 'data-scientist'\n",
        "\n",
        "\n",
        "client = MongoClient('localhost', 27017)\n",
        "db = client['hh_vacancies']\n",
        "collection = db.data_scientist\n",
        "\n",
        "url = 'https://hh.ru'\n",
        "suffix = '/vacancies/' + occupation\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:95.0) Gecko/20100101 Firefox/95.0'}\n",
        "info = []\n",
        "last_page = False\n",
        "page = 0\n",
        "\n",
        "while True:\n",
        "  params = {'page': str(page)}\n",
        "  time.sleep(uniform(1, 3))\n",
        "  response = requests.get(url + suffix, params=params, headers=headers)\n",
        "  dom = BS(response.text, 'html.parser')\n",
        "  vacancies = dom.find_all('div', {'class':'vacancy-serp-item-body__main-info'})\n",
        "  vacancies_list = []\n",
        "  for vacancy in vacancies:\n",
        "    vacancy_data = {}\n",
        "    vac_info = vacancy.contents[0]\n",
        "    link_name = vac_info.find('h3').contents[0].contents[0]\n",
        "    vacancy_data['name'] = link_name.string\n",
        "    vacancy_data['link'] = link_name.find('a')['href']\n",
        "    try:\n",
        "      salary = vac_info.find('span', {'class':'bloko-header-section-3'}).text\n",
        "      s = re.findall('\\d+', salary.replace('\\u202f', ''))\n",
        "      if 'от' in salary:\n",
        "        vacancy_data['salary_from']= int(s[0])\n",
        "        vacancy_data['salary_to'] = np.nan\n",
        "        vacancy_data['salary_currency'] = salary[salary.rfind(' '):]\n",
        "      elif 'до' in salary:\n",
        "        vacancy_data['salary_from'] = np.nan\n",
        "        vacancy_data['salary_to'] = int(s[0])\n",
        "        vacancy_data['salary_currency'] = salary[salary.rfind(' '):]\n",
        "      else:\n",
        "        vacancy_data['salary_from'] = int(s[0])\n",
        "        vacancy_data['salary_to'] = int(s[1])\n",
        "        vacancy_data['salary_currency'] = salary[salary.rfind(' '):]\n",
        "    except:\n",
        "      vacancy_data['salary_from'] = np.nan\n",
        "      vacancy_data['salary_to'] = np.nan\n",
        "      vacancy_data['salary_currency'] = np.nan\n",
        "\n",
        "    vacancy_data['_id'] = vacancy_data['link']\n",
        "\n",
        "    try:\n",
        "      collection.insert_one(vacancy_data)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  if dom.find('div', {'class':'pager'}).find('a', {'data-qa' : 'pager-next'}) != None:\n",
        "    page += 1\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary = 120000\n",
        "\n",
        "res = collection.find({'$or' : [\n",
        "    {'salary_from':{'$gt':salary}},\n",
        "    {'salary_to':{'$gt':salary}}]})\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "id": "-htF_al9cDZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}